{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miglesia/anaconda2/envs/my_pymc_env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/miglesia/anaconda2/envs/my_pymc_env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './modules/../classifications/atlas_international_product_space_hs4_codes.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3c48998ef918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mHH_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0md3plus2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md3plus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/YSI_NA_Convening/modules/d3plus2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mProductSpace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD3PlusViz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mHS_GRAPH_DATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../classifications/atlas_international_product_space_hs4_codes.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/YSI_NA_Convening/modules/d3plus2.py\u001b[0m in \u001b[0;36mProductSpace\u001b[0;34m()\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mProductSpace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD3PlusViz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mHS_GRAPH_DATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../classifications/atlas_international_product_space_hs4_codes.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mSITC_GRAPH_DATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../classifications/atlas_international_product_space_sitc_codes.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './modules/../classifications/atlas_international_product_space_hs4_codes.json'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./modules/\") # for d3plus2\n",
    "\n",
    "sys.path.append(\"./../Hidalgo_Haussmann\") # for HH tools\n",
    "from HH_tools import *\n",
    "\n",
    "import d3plus2 as d3plus\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './../growth-lab-diversity/data/sources/'\n",
    "agglevel_titles = pd.read_csv(path+'agglevel_titles.csv')\n",
    "area_titles = pd.read_csv(path+'area_titles.csv')\n",
    "industry_titles = pd.read_csv(path+'industry_titles.csv')\n",
    "industry_titles =  pd.DataFrame([['POPESTIMATE2010','Population']], columns = industry_titles.columns).append(industry_titles).reset_index(drop = True)\n",
    "industry_titles =  pd.DataFrame([['Cropland','Cropland'],\n",
    "                                ['Desert','Desert'],\n",
    "                                ['Grassland','Grassland'],\n",
    "                                ['Other','Other'],\n",
    "                                ['Woodland','Woodland'],\n",
    "                                ['Urban','Urban'],\n",
    "                                ['Water','Water']], columns = industry_titles.columns).append(industry_titles).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './../growth-lab-diversity/data/sources/BLS/'\n",
    "\n",
    "uc = ['area_fips', 'industry_code', 'agglvl_code', 'year', 'annual_avg_estabs', 'annual_avg_emplvl', 'total_annual_wages']\n",
    "\n",
    "df_list = []\n",
    "for y in np.arange(2006, 2016):\n",
    "    df_y = pd.read_csv(path+str(y)+'_annual_singlefile.zip', usecols = uc, low_memory=False)\n",
    "    df_list += [df_y]\n",
    "    \n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get robustness from using 10 years\n",
    "\n",
    "variable = 'annual_avg_estabs'\n",
    "#correct possible mistakes, index should be like c-p-y\n",
    "cpy_ix = df.loc[df.agglvl_code == 76].groupby(['year', 'area_fips', 'industry_code'])[[variable]].sum()\n",
    "year_avg = cpy_ix.reset_index().drop('year', axis = 1).groupby(['area_fips', 'industry_code'])[[variable]].mean()\n",
    "# summary_var = df_2015.drop('year', axis = 1).loc[df_2015.agglvl_code == 76].groupby(['area_fips', 'industry_code'])[[variable]].sum()\n",
    "X = year_avg.unstack()[variable]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population and land uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add population\n",
    "\n",
    "county_LU = pd.read_csv('./data/US_land_use/land_use_frac.csv', index_col=0)\n",
    "county_LU.index = county_LU.index.astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(log10(county_LU['Woodland']).dropna(), 50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add population\n",
    "\n",
    "county_pop = pd.read_csv('./data/co-est2017-alldata.csv', encoding = 'latin-1')\n",
    "county_pop['area_fips'] = county_pop.STATE.astype(str).str.zfill(2) + county_pop.COUNTY.astype(str).str.zfill(3)\n",
    "\n",
    "county_pop = county_pop[['area_fips', 'POPESTIMATE2010']].set_index('area_fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([county_pop.loc[X.index], county_LU.loc[X.index], X], axis = 1, sort = True)#.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check sparsity / small areas\n",
    "# # df_ = summary_var.groupby('area_fips').count().sort_values(by = variable)\n",
    "# # pd.concat([df_, industry_titles.set_index('industry_code')], axis = 1, sort = False)\n",
    "# # pd.concat([df_, area_titles.set_index('area_fips')], axis = 1, sort = False).dropna()\n",
    "\n",
    "# # # Check what different choices do. \n",
    "# # # Final recommendation, take logs, don't fill gaps and use min periods >~ 20. (meth_3)\n",
    "\n",
    "# # meth_1 = log10(summary_var.unstack()[variable]).fillna(-2).cov()\n",
    "# # meth_2 = log10(summary_var.unstack()[variable]).fillna(-1).cov()\n",
    "# # meth_3 = log10(summary_var.unstack()[variable]).cov(min_periods = 20).fillna(0)\n",
    "\n",
    "# # plt.hist(meth_1.values.flatten().clip(-100, 1000), 100, linewidth = 0, alpha = .4)\n",
    "# # plt.hist(meth_2.values.flatten().clip(-100, 1000), 100, linewidth = 0, alpha = .4)\n",
    "# # plt.hist(meth_3.values.flatten().clip(-100, 1000), 100, linewidth = 0, alpha = .4)\n",
    "# # plt.show()\n",
    "\n",
    "# # x = meth_2.iloc[40] # meth_2.stack()\n",
    "# # y = meth_3.iloc[40] # meth_3.stack()\n",
    "# # plt.plot(x.values, y.values, marker = '.', alpha = .2, linewidth = 0)\n",
    "\n",
    "# # M = log10(X)\n",
    "# # M = (M.T - M.T.mean()).T\n",
    "\n",
    "# cor_mat = log10(X).corr(min_periods = 20) # M -->log10(X)\n",
    "# cov_mat = log10(X).cov(min_periods = 20)\n",
    "\n",
    "# # We should be able to compare this to pearson correlation. \n",
    "# # However, removing area mean is necesary for this but note that row/col means are ill defined cause of logs of missing data... \n",
    "# # Here covariance can be compared to Pearson and plotted directly. It seems cov ~ pears^2\n",
    "\n",
    "# # XTX = log10(X).T.fillna(0).dot(log10(X).fillna(0))\n",
    "# # norm = np.sqrt(np.square(XTX).sum())\n",
    "# # XTX = XTX.div(norm, axis = 0).div(norm) # this would convert it to Pearson if it was centered\n",
    "\n",
    "# x = cor_mat.stack()\n",
    "# y = cov_mat.stack()\n",
    "# fig, ax = plt.subplots(1, figsize = (10, 10))\n",
    "# ax.plot(x.values, y.values, marker = '.', alpha = .002, linewidth = 0)\n",
    "# # ax.plot(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100)**2)\n",
    "# ax.set_xlim(-.2, 1.1); ax.set_ylim(-.2, 1.1); #ax.set_ylim(0, 0.00001)\n",
    "# ax.set_xlabel('Correlation'); ax.set_ylabel('Covariance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_mat = log10(X).corr(min_periods = 20)\n",
    "cov_mat = log10(X).cov(min_periods = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demean(Z):\n",
    "    Z = Z.fillna(0)\n",
    "    means = Z.mean()\n",
    "    return (Z.T - means).T - means + means.mean()\n",
    "\n",
    "def stand(Z):\n",
    "    Z = Z.fillna(0)\n",
    "    std = Z.std()\n",
    "    return Z.T.div(std).T.div(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat = demean(cor_mat.fillna(0))\n",
    "# mat = cor_mat\n",
    "fig, axs = plt.subplots(1, 3, figsize = (24, 8))\n",
    "\n",
    "axs[0].matshow(demean(stand(demean(cor_mat))), vmin = -10, vmax = 10)\n",
    "axs[1].matshow(demean(cor_mat), vmin = -.1, vmax = .1)\n",
    "axs[2].matshow(cor_mat.fillna(0), vmin = .2, vmax = .7)\n",
    "\n",
    "# plt.hist(stand(demean(cor_mat)).std(), 30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try spectral clustering. Works when matrix is demeaned\n",
    "from sklearn.cluster import SpectralClustering\n",
    "X_ = demean(cor_mat).values\n",
    "clustering = SpectralClustering(n_clusters=10,\n",
    "        assign_labels=\"discretize\",\n",
    "        random_state=0).fit(X_)\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "clust_result = pd.DataFrame(clustering.labels_, index = X.columns, columns = ['cluster'])\n",
    "clust_result = pd.concat([clust_result, industry_titles.set_index('industry_code')], axis = 1, sort = False).dropna().sort_values(by = ['cluster', 'industry_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edges = pd.DataFrame(demean(cor_mat).stack(), columns = ['dem_corr'])\n",
    "# > demean(cor_mat).values, 90\n",
    "# edges.loc[]\n",
    "edges_s = edges.loc[edges.dem_corr > edges.dem_corr.quantile(.9)]\n",
    "edges_s.index.names = ['industry_code_x', 'industry_code_y']\n",
    "edges_s = edges_s.reset_index().merge(\n",
    "    industry_titles, left_on = 'industry_code_x', right_on = 'industry_code').merge(\n",
    "    industry_titles, left_on = 'industry_code_y', right_on = 'industry_code').T.drop_duplicates().T\n",
    "edges_s['dem_corr'] = edges_s['dem_corr'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load modules\n",
    "# from numpy.random import choice \n",
    "# from numpy import where, power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# nodes = industry_titles\n",
    "\n",
    "nodes_size = pd.DataFrame(np.sqrt(X.sum()), columns=['sqrt_size'])\n",
    "nodes = pd.concat([nodes_size, clust_result], axis = 1, sort = False)\n",
    "\n",
    "norm = mcolors.Normalize(vmin=0, vmax=10, clip=True)\n",
    "mapper = plt.cm.ScalarMappable(norm=norm, cmap=plt.cm.jet)\n",
    "\n",
    "nodes['color'] = nodes['cluster'].apply(lambda x: mcolors.rgb2hex(mapper.to_rgba(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_d = 40\n",
    "weight_column = 'dem_corr' #'weight_'+geo\n",
    "\n",
    "        ### Max degree = max_d. Parameter used to trim the network.\n",
    "df1 = edges_s.groupby('industry_code_x').apply(lambda x: x.nlargest(max_d, weight_column)).reset_index(drop = True)\n",
    "df2 = edges_s.groupby('industry_code_y').apply(lambda x: x.nlargest(max_d, weight_column)).reset_index(drop = True)\n",
    "edges_max_d = df1.merge(df2, on = ['industry_code_x', 'industry_title_x', 'industry_code_y', 'industry_title_x', weight_column]).reset_index(drop = True)\n",
    "\n",
    "###\n",
    "\n",
    "# Hard threshold and max degree backboning\n",
    "\n",
    "G = nx.from_pandas_edgelist(edges_max_d, 'industry_code_x', 'industry_code_y', weight_column)\n",
    "\n",
    "\n",
    "plt.figure(figsize = (10, 8))\n",
    "\n",
    "G = max(nx.connected_component_subgraphs(G), key=len)\n",
    "nodes_s = nodes.loc[G.nodes.keys()]\n",
    "pos = nx.spring_layout(G, k=.4)\n",
    "\n",
    "nx.draw(G, pos, node_size = nodes_s.sqrt_size.values, alpha=.6, node_color= list(nodes_s.color.values), edgelist = [])\n",
    "nx.draw_networkx_edges(G, pos, edge_color='.7', alpha=.3)\n",
    "# plt.title('max_d = '+str(max_d))\n",
    "#     plt.savefig('./Figures/5_max_deg/'+col_name+'_plot1.png')\n",
    "#             plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw in d3plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes\n",
    "pos_df = pd.DataFrame(pos, index = ['x', 'y']).T\n",
    "nodes_wpos = pd.concat([nodes_s, pos_df], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_ = nodes_wpos.reset_index()[['index','x', 'y', 'industry_title', 'color']].dropna(subset = ['x']).rename({'index': 'id'}, axis = 1)\n",
    "nodes_['id'] = nodes_['id'].astype(str).str.zfill(4)\n",
    "nodes_[['x', 'y']] = 500 * nodes_[['x', 'y']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes_.sort_values(by = 'id')#.loc[nodes_.id == 'Desert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../Hidalgo_Haussmann\") # for HH tools\n",
    "import pandas as pd\n",
    "from HH_tools import robust_proximity, year_to_tp, RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_['presence'] = True\n",
    "\n",
    "edges_max_d['edge_tuple'] = list(zip(edges_max_d.industry_code_x, edges_max_d.industry_code_y))\n",
    "edges_max_d['edge_tuple_rev'] = list(zip(edges_max_d.industry_code_y, edges_max_d.industry_code_x))\n",
    "edges_max_d_triangles = edges_max_d.loc[edges_max_d.edge_tuple.isin(G.edges()) | edges_max_d.edge_tuple_rev.isin(G.edges())]\n",
    "\n",
    "links = edges_max_d_triangles.reset_index().rename({weight_column: 'strength'},axis = 1)\n",
    "links['target'] = links['industry_code_y'].astype(str).str.zfill(4)\n",
    "links['source'] = links['industry_code_x'].astype(str).str.zfill(4)\n",
    "\n",
    "# links = nc_backbone.reset_index().rename({'score': 'strength'},axis = 1)\n",
    "# links['target'] = links['trg'].astype(str).str.zfill(4)\n",
    "# links['source'] = links['src'].astype(str).str.zfill(4)\n",
    "\n",
    "network = '{\"nodes\": '+nodes_.to_json(orient= 'records')+', \"edges\": '+links[['index', 'source', 'target']].to_json(orient= 'records')+'}\\n'\n",
    "# network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conditional coloring\n",
    "\n",
    "# Manufacturing (light_blue) and services (yellow)\n",
    "nodes_['color_mfg_srv'] = 'D3D3D3' #Gray bckg\n",
    "\n",
    "conditions = [\n",
    "    (nodes_['industry_title'].str.lower().str.contains('manufacturing')) + (nodes_['industry_title'].str.lower().str.contains('mfg')),\n",
    "    (nodes_['industry_title'].str.lower().str.contains('service')),# or (nodes_['industry_title'].str.lower().str.contains('mfg')),\n",
    "    (nodes_['industry_title'].str.lower().str.contains('wholesale')),# or (nodes_['industry_title'].str.lower().str.contains('mfg')),\n",
    "    (-nodes_['industry_title'].str.lower().str.contains('naics'))]\n",
    "\n",
    "choices = ['#000080', '#ffc400', '#00b0ff', '#000000']\n",
    "\n",
    "nodes_['color_mfg_srv'] = np.select(conditions, choices, default='#D3D3D3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_max_d_triangles.to_csv('edges_max_d_triangles.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = d3plus.ProductSpace(\n",
    "id=\"name\",\n",
    "name=\"industry_title\",\n",
    "color=\"color_mfg_srv\",\n",
    "graph_data=network,\n",
    "presence=\"presence\",\n",
    "edge_property=\"edges\",\n",
    "network_id=\"id\")\n",
    "ps.draw(nodes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = d3plus.ProductSpace(\n",
    "id=\"name\",\n",
    "name=\"industry_title\",\n",
    "color=\"color\",\n",
    "graph_data=network,\n",
    "presence=\"presence\",\n",
    "edge_property=\"edges\",\n",
    "network_id=\"id\")\n",
    "ps.draw(nodes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activities by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "summary = nodes.loc[nodes.industry_title.str.contains('NAICS')].groupby('cluster').agg({'industry_title': 'first', 'color':[ 'first', 'count']})\n",
    "summary.columns = ['color', 'node_count','example']\n",
    "summary.sort_index()#.sort_values(by = 'node_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_['color'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# land-use clusters\n",
    "nodes_.loc[nodes_['color'].isin(['#f10800', '#ff6800', '#ceff29', '#29ffce'])].sort_values(by = ['color','industry_title'])\n",
    "\n",
    "#population cluster\n",
    "nodes_.loc[nodes_['color'].isin(['#7dff7a'])].sort_values(by = ['color','industry_title'])\n",
    "\n",
    "#'yellow' services cluster\n",
    "nodes_.loc[nodes_['color'].isin(['#ffc400'])].sort_values(by = ['color','industry_title'])\n",
    "\n",
    "#state/public sector cluster\n",
    "# nodes_.loc[nodes_['color'].isin(['#004cff'])].sort_values(by = ['color','industry_title'])\n",
    "\n",
    "#others/mfg clusters\n",
    "# nodes_.loc[nodes_['color'].isin(['#000080', '#0000f1', '#00b0ff'])].sort_values(by = ['industry_title'])\n",
    "\n",
    "# coastal?\n",
    "# nodes_.loc[nodes_['color'].isin(['#0000f1'])].sort_values(by = ['color','industry_title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cluster 7, #ffc400 are 76 nodes that follow neither population nor land resources. Then what is it all about?\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import colorlover as cl    \n",
    "    \n",
    "for clsr in range(10):\n",
    "    try:\n",
    "        \n",
    "        text = nodes.loc[nodes.cluster == clsr]['industry_title']\n",
    "\n",
    "        r1 = text.str.lower().str.split().values\n",
    "        r1 = [item for sublist in r1 for item in sublist]\n",
    "\n",
    "        r1_f = [w.replace(',', '').replace('mfg.', 'manufacturing') for w in r1 if not w in stop_words] \n",
    "\n",
    "        print(summary.loc[clsr])\n",
    "        color = summary.loc[clsr]['color']\n",
    "        display(HTML(cl.to_html( [tuple(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2 ,4))] )))\n",
    "        print(Counter(r1_f).most_common()[:10])\n",
    "        print('\\n')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map distribution from different clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes\n",
    "import geopandas as gpd\n",
    "\n",
    "counties = gpd.read_file('./data/cb_2017_us_county_500k/cb_2017_us_county_500k.shp')\n",
    "counties['area_fips'] = counties.STATEFP + counties.COUNTYFP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### A little trick. Distribution of neigbors of node 'Naics 5417 Scientific Research and Development Services'\n",
    "# nodes_.loc[nodes_.id == '5417']\n",
    "ego_node = 'Desert' #'Cropland' #'POPESTIMATE2010'# '5417'\n",
    "\n",
    "neigh = edges_max_d_triangles.loc[(edges_max_d_triangles.industry_code_x == ego_node) |\n",
    "                                  (edges_max_d_triangles.industry_code_y == ego_node)]\n",
    "neigh_ids = list(set(neigh['industry_code_x'].unique()).union(set(neigh['industry_code_y'].unique())))\n",
    "# nodes_.loc[nodes_.id.isin(neigh_ids)]['id'].values\n",
    "\n",
    "node_ids = neigh_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.loc[gdf.industry_code == naics]['annual_avg_estabs']\n",
    "# df_neigh\n",
    "# df_neigh.groupby('industry_code').mean().sort_values(by = 'annual_avg_estabs').tail(5).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Choose indus to process...\n",
    "n = 5\n",
    "merged = df_agglv_yravg.groupby(level = 1)['annual_avg_estabs'].sum().reset_index().merge(nodes_, left_on = 'industry_code', right_on = 'id')\n",
    "display_indus = merged.loc[merged.groupby('color')['annual_avg_estabs'].nlargest(n).index.get_level_values(1)]\n",
    "\n",
    "#Filter original data to have these neighboring industries\n",
    "df_agglv = df.loc[df.agglvl_code == 76]\n",
    "\n",
    "df_agglv_yravg = df_agglv.groupby(['area_fips', 'industry_code']).mean().drop(['agglvl_code','year'], axis = 1)\n",
    "# df_indu_prc_area = df_agglv_yravg.groupby(level=0).apply(lambda x: 100 * x / x.sum())\n",
    "df_indu_prc_area = log10(df_agglv_yravg)\n",
    "\n",
    "df_ = df_indu_prc_area.reset_index()\n",
    "\n",
    "i = 0\n",
    "open('./Figures/7_compo_USA_nw/labels.txt', 'w').close()\n",
    "for color in nodes_.color.unique():\n",
    "  \n",
    "    cluster_ids = nodes_.loc[nodes_.color == color]['id']\n",
    "    node_ids = cluster_ids.values\n",
    "    \n",
    "    df_neigh = df_.loc[df_.industry_code.isin(nodes_.loc[nodes_.id.isin(node_ids)]['id'].values)]\n",
    "    df_neigh = df_neigh.set_index('area_fips')\n",
    "    \n",
    "    counties_ = counties.set_index('area_fips').reindex(df_neigh.index)[['geometry']]\n",
    "    gdf = gpd.GeoDataFrame(pd.concat([df_neigh, counties_], axis = 1, sort = True).dropna())\n",
    "\n",
    "    # Sample of cluster color\n",
    "    rgb_tuple = tuple(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2 ,4))\n",
    "    im = Image.new('RGBA', (20, 20), rgb_tuple)\n",
    "    im.save('./Figures/7_compo_USA_nw/cp_'+str(i)+'.png')\n",
    "\n",
    "    for naics in display_indus['industry_code'].values:\n",
    "        if( gdf.loc[gdf.industry_code == naics]['annual_avg_estabs'].mean() > .2 ):#& (i <=5): # Dismiss small indus\n",
    "            node_info = nodes_.loc[nodes_.id == naics]\n",
    "            \n",
    "            # send node labels to test (they will then go to svg of figure)\n",
    "            with open('./Figures/7_compo_USA_nw/labels.txt', 'a') as f:\n",
    "                f.write(node_info['industry_title'].values[0]+'\\n')\n",
    "            display(node_info)\n",
    "            display(HTML(cl.to_html( [rgb_tuple] )))\n",
    "\n",
    "            ax = gdf.loc[gdf.industry_code == naics].plot(\n",
    "                column='annual_avg_estabs', cmap=plt.cm.gist_yarg, vmin = 0, vmax = 1.5, linewidth = 0, figsize = (10, 6.5))\n",
    "            ax.set_xlim(-130, -60)\n",
    "            ax.set_ylim(22, 50)#, figsize=figsize, scheme='equal_interval', k=colors, legend=True)\n",
    "#             plt.axis('off')\n",
    "            ax.get_xaxis().set_ticks([])\n",
    "            ax.get_yaxis().set_ticks([])\n",
    "            plt.text(-128, 23.5, 'NAICS '+str(node_info['id'].values[0]), fontsize=30) # position in lat lon\n",
    "            plt.savefig('./Figures/7_compo_USA_nw/'+str(node_info['id'].values[0])+'.png', bbox_inches = 'tight')\n",
    "            plt.show()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TXT2InkscapeXMLv3.py\n",
    "\n",
    "# A simple Python 3 script to look through a list of text and\n",
    "# turn each line into an xml entry for use in Inkscape.\n",
    "# in this script we will slightly spread the text to allow\n",
    "# the user a better chance of retaining the order of their\n",
    "# initial text.  Inkscape can be used to spread it out\n",
    "# using the Align and Distribute Tool.\n",
    "\n",
    "\n",
    "ofilenm = './Figures/7_compo_USA_nw/figure.svg'#str(input(\"What is the filename you wish for output?\"))\n",
    "outfile = open(ofilenm,\"w\")\n",
    "\n",
    "ListFlm = './Figures/7_compo_USA_nw/labels.txt'#str(input(\"What is the name and location of the TXT file to work with?\"))\n",
    "\n",
    "Loctn = 75 #Vertical position to start text insertion\n",
    "SpacingV = 25  #The vertical spacing between lines.\n",
    "\n",
    "# The block that follows is the Inkscape standard header.\n",
    "TextBlockA = '''<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
    "<!-- Created with Inkscape (http://www.inkscape.org/) -->\n",
    "\n",
    "<svg\n",
    "   xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n",
    "   xmlns:cc=\"http://creativecommons.org/ns#\"\n",
    "   xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
    "   xmlns:svg=\"http://www.w3.org/2000/svg\"\n",
    "   xmlns=\"http://www.w3.org/2000/svg\"\n",
    "   xmlns:sodipodi=\"http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd\"\n",
    "   xmlns:inkscape=\"http://www.inkscape.org/namespaces/inkscape\"\n",
    "   width=\"744.09448819\"\n",
    "   height=\"1052.3622047\"\n",
    "   id=\"svg2\"\n",
    "   version=\"1.1\"\n",
    "   inkscape:version=\"0.48.4 r9939\"\n",
    "   sodipodi:docname=\"New document 1\">\n",
    "  <defs\n",
    "     id=\"defs4\" />\n",
    "  <sodipodi:namedview\n",
    "     id=\"base\"\n",
    "     pagecolor=\"#ffffff\"\n",
    "     bordercolor=\"#666666\"\n",
    "     borderopacity=\"1.0\"\n",
    "     inkscape:pageopacity=\"0.0\"\n",
    "     inkscape:pageshadow=\"2\"\n",
    "     inkscape:zoom=\"0.35\"\n",
    "     inkscape:cx=\"375\"\n",
    "     inkscape:cy=\"520\"\n",
    "     inkscape:document-units=\"px\"\n",
    "     inkscape:current-layer=\"layer1\"\n",
    "     showgrid=\"false\"\n",
    "     inkscape:window-width=\"1280\"\n",
    "     inkscape:window-height=\"742\"\n",
    "     inkscape:window-x=\"-2\"\n",
    "     inkscape:window-y=\"-3\"\n",
    "     inkscape:window-maximized=\"1\" />\n",
    "  <metadata\n",
    "     id=\"metadata7\">\n",
    "    <rdf:RDF>\n",
    "      <cc:Work\n",
    "         rdf:about=\"\">\n",
    "        <dc:format>image/svg+xml</dc:format>\n",
    "        <dc:type\n",
    "           rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\" />\n",
    "        <dc:title></dc:title>\n",
    "      </cc:Work>\n",
    "    </rdf:RDF>\n",
    "  </metadata>\n",
    "  <g\n",
    "     inkscape:label=\"Layer 1\"\n",
    "     inkscape:groupmode=\"layer\"\n",
    "     id=\"layer1\">'''\n",
    "\n",
    "TextBlockB = '''<text\\n\n",
    "        xml:space=\"preserve\"\n",
    "        style=\"font-size:20px;font-style:normal;font-weight:normal;line-height:125%;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;font-family:Sans\"\n",
    "        x=\"93.910118\"\n",
    "        y=\"'''\n",
    "TextBlockC = '''id=\"text2989\"\n",
    "        sodipodi:linespacing=\"150%\"><tspan\n",
    "            sodipodi:role=\"line\"\n",
    "            id=\"tspan2991\"\n",
    "            x=\"93.910118\"\n",
    "            y=\"'''\n",
    "\n",
    "outfile.write(TextBlockA)\n",
    "\n",
    "# The section that follows is to build the SVG text elements\n",
    "f = open(ListFlm,\"r\")\n",
    "for line in f:\n",
    "    TXTLine = line.strip()\n",
    "    Loctn = Loctn + SpacingV\n",
    "    InsertStrng1 = str(Loctn)+'\"\\n'\n",
    "    InsertStrng2= str(Loctn)+'\">'+TXTLine+'</tspan></text>\\n'\n",
    "    outfile.write(TextBlockB)\n",
    "    outfile.write(InsertStrng1)\n",
    "    outfile.write(TextBlockC)\n",
    "    outfile.write(InsertStrng2)\n",
    "\n",
    "# The next section is the close off for the SVG xml.\n",
    "\n",
    "outfile.write('  </g>\\n')\n",
    "outfile.write('</svg>\\n')\n",
    "\n",
    "outfile.close()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose indus to process...\n",
    "n = 5\n",
    "merged = df_agglv_yravg.groupby(level = 1)['annual_avg_estabs'].sum().reset_index().merge(nodes_, left_on = 'industry_code', right_on = 'id')\n",
    "display_indus = merged.loc[merged.groupby('color')['annual_avg_estabs'].nlargest(n).index.get_level_values(1)]\n",
    "\n",
    "#Filter original data to have these neighboring industries\n",
    "df_agglv = df.loc[df.agglvl_code == 76]\n",
    "\n",
    "df_agglv_yravg = df_agglv.groupby(['area_fips', 'industry_code']).mean().drop(['agglvl_code','year'], axis = 1)\n",
    "# df_indu_prc_area = df_agglv_yravg.groupby(level=0).apply(lambda x: 100 * x / x.sum())\n",
    "df_indu_prc_area = log10(df_agglv_yravg)\n",
    "\n",
    "df_ = df_indu_prc_area.reset_index()\n",
    "\n",
    "for color in nodes_.color.unique():\n",
    "  \n",
    "    cluster_ids = nodes_.loc[nodes_.color == color]['id']\n",
    "    node_ids = cluster_ids.values\n",
    "    \n",
    "    df_neigh = df_.loc[df_.industry_code.isin(nodes_.loc[nodes_.id.isin(node_ids)]['id'].values)]\n",
    "    df_neigh = df_neigh.set_index('area_fips')\n",
    "    \n",
    "    counties_ = counties.set_index('area_fips').reindex(df_neigh.index)[['geometry']]\n",
    "    gdf = gpd.GeoDataFrame(pd.concat([df_neigh, counties_], axis = 1, sort = True).dropna())\n",
    "    \n",
    "    for naics in display_indus['industry_code'].values:\n",
    "        if( gdf.loc[gdf.industry_code == naics]['annual_avg_estabs'].mean() > .45 ):#& (i <=5): # Dismiss small indus\n",
    "            display(nodes_.loc[nodes_.id == naics])\n",
    "            display(HTML(cl.to_html( [tuple(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2 ,4))] )))\n",
    "\n",
    "            ax = gdf.loc[gdf.industry_code == naics].plot(\n",
    "                column='annual_avg_estabs', cmap=plt.cm.gist_yarg, vmin = 0, vmax = 1.5, linewidth = 0, figsize = (10, 6.5))\n",
    "            ax.set_xlim(-130, -60)\n",
    "            ax.set_ylim(22, 50)#, figsize=figsize, scheme='equal_interval', k=colors, legend=True)\n",
    "            plt.show()\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color by Population Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = './../../../../../media/miglesia/Elements/corr_st_data/'\n",
    "\n",
    "main_tables = pd.concat([pd.read_csv('./../../../../../media/miglesia/Elements/corr_st_data/CHI_COM_W4_O4_E2_I4_main_table_2011_2012.csv'),\n",
    "           pd.read_csv('./../../../../../media/miglesia/Elements/corr_st_data/CHI_COM_W4_O4_E2_I4_main_table_2011_2013.csv'),\n",
    "           pd.read_csv('./../../../../../media/miglesia/Elements/corr_st_data/CHI_COM_W4_O4_E2_I4_main_table_2012_2013.csv'),\n",
    "           pd.read_csv('./../../../../../media/miglesia/Elements/corr_st_data/CHI_COM_W4_O4_E2_I4_main_table_2014_2011.csv'),\n",
    "           pd.read_csv('./../../../../../media/miglesia/Elements/corr_st_data/CHI_COM_W4_O4_E2_I4_main_table_2014_2012.csv'),\n",
    "           pd.read_csv('./../../../../../media/miglesia/Elements/corr_st_data/CHI_COM_W4_O4_E2_I4_main_table_2014_2013.csv')])\n",
    "\n",
    "main_table = main_tables.groupby('CHI ID COM').mean()/2.\n",
    "\n",
    "# change node names into node index\n",
    "# main_table.rename(columns = dict(zip(nodes.node_name, nodes.index)), inplace = True)\n",
    "\n",
    "population = pd.read_csv('./data/pop_dist_comuna.csv').rename(columns = {'comuna_id': 'CHI ID COM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log10\n",
    "population['log_dens'] = log10(population['densidad'])\n",
    "b = 8; population['log_dens_cat'] = pd.cut(population['log_dens'], b)\n",
    "\n",
    "bins = pd.cut(population['log_dens'], b, retbins=True)[1]\n",
    "bins_mean = (bins[1:] + bins[:-1])/2.\n",
    "\n",
    "merged = pd.concat([population.set_index('CHI ID COM')[['log_dens_cat']].sort_index(), main_table], axis = 1)\n",
    "popdens_RCA = RCA(merged.groupby('log_dens_cat').sum())\n",
    "\n",
    "popdens_RCA_normed = popdens_RCA/popdens_RCA.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop_dens_index = pd.DataFrame((popdens_RCA_normed.T*bins_mean).T.sum(), columns = ['pop_dens_index'])\n",
    "# pop_dens_index = pop_dens_index.reset_index().rename(columns={'index':'id'})\n",
    "# nodes_ = nodes_.merge(pop_dens_index, on = 'id', how = 'left') # industry_title / node_name\n",
    "# # nodes_['pop_dens_color_code'] = pd.cut(nodes_['pop_dens_index'], bins = 7, labels=False)\n",
    "\n",
    "# from numpy import nan\n",
    "# rainbow_colors = {0:'#9400D3', #Violet\n",
    "# 1:'#4B0082', #Indigo\n",
    "# 2:'#0000FF', #Blue\n",
    "# 3:'#00FF00', #Green\n",
    "# nan:'#D3D3D3',  #'#D3D3D3', #Gray\n",
    "# 4:'#FFFF00', #Yellow\n",
    "# 5:'#FF7F00', #Orange\n",
    "# 6:'#FF0000'} #Red\n",
    "\n",
    "# nodes_['color_2'] = pd.DataFrame(nodes_['pop_dens_color_code'].map(rainbow_colors))\n",
    "\n",
    "# network = '{\"nodes\": '+nodes_.to_json(orient= 'records')+', \"edges\": '+links[['index', 'source', 'target']].to_json(orient= 'records')+'}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ps = d3plus.ProductSpace(\n",
    "id=\"name\",\n",
    "name=\"node_name\",\n",
    "color=\"color_2\",\n",
    "graph_data=network,\n",
    "presence=\"presence\",\n",
    "edge_property=\"edges\",\n",
    "network_id=\"id\")\n",
    "ps.draw(nodes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(edges.weight_CHI_COM.values, 50)\n",
    "plt.hist(edges_max_d.weight_CHI_COM.values, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
