{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate decaying correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miglesia/anaconda2/envs/my_pymc_env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/miglesia/anaconda2/envs/my_pymc_env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ref = pd.read_csv('./state_ref.csv')\n",
    "state_ref['STATEFP'] = state_ref['STATEFP'].astype(str).str.zfill(2)\n",
    "\n",
    "# counties = gpd.read_file('county_shp/cb_2013_us_county_20m.shp')\n",
    "# counties['AREA_FIPS'] = counties['STATEFP'] + counties['COUNTYFP']\n",
    "\n",
    "# GeoDataFrame used for telling which counties do points belong to\n",
    "# gdf = counties[['ALAND', 'AREA_FIPS', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "no such file or directory: 'NG_point_1.shp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-179ecff1cb97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mindu_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NG_point_1.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mindu_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'epsg:4326'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mindu_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindu_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_ref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'STATE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'STATEFP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mindu_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindu_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'within'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/my_pymc_env/lib/python3.6/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, bbox, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/my_pymc_env/lib/python3.6/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no such archive file: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no such file or directory: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[1;32m    164\u001b[0m                        \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvsi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvsi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: no such file or directory: 'NG_point_1.shp'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "indu_p = gpd.read_file('NG_point_1.shp'); indu_p.crs = {'init': 'epsg:4326'}\n",
    "indu_p = indu_p.merge(state_ref[['STATE', 'STATEFP']])\n",
    "indu_p = gpd.sjoin(indu_p, gdf, op='within')\n",
    "\n",
    "# Get coordinates in separate columns\n",
    "loc_values = np.array([(p.x, p.y) for p in indu_p.geometry])\n",
    "indu_p['loc_x'] = loc_values[:, 0]\n",
    "indu_p['loc_y'] = loc_values[:, 1]\n",
    "\n",
    "# Project to easting northing so to have meters. UTM 14S is on US midwest.\n",
    "from pyproj import Proj\n",
    "\n",
    "myProj = Proj(\"+proj=utm +zone=14S, +north +ellps=WGS84 +datum=WGS84 +units=m +no_defs\")\n",
    "\n",
    "# Project\n",
    "indu_p['loc_x'], indu_p['loc_y'] = myProj(indu_p['loc_x'].values, indu_p['loc_y'].values)\n",
    "# Units from meters to km\n",
    "indu_p['loc_x']  = indu_p['loc_x']/1e3; \n",
    "indu_p['loc_y']  = indu_p['loc_y']/1e3; \n",
    "\n",
    "plt.scatter(indu_p['loc_x'], indu_p['loc_y']) # Units seem to be milimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test. One plant per county.\n",
    "# indu_p = indu_p.groupby('AREA_FIPS').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "\n",
    "indu_q = indu_p.copy()[['CAPACITY', 'geometry']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = [1, 3, 6, 10, 30, 60, 100]#[.1, .3, 1, 3, 10, 30, 100, 300];  # distance used in letting corr decay\n",
    "D = len(dist)\n",
    "N = 3\n",
    "cov_results = np.zeros((D, N))\n",
    "\n",
    "x_0 = indu_p['loc_x']\n",
    "y_0 = indu_p['loc_y']\n",
    "\n",
    "for d in range(D):\n",
    "    for n in range(N):\n",
    "        \n",
    "        x_col = 'loc_d'+str(d)+'n'+str(n)+'_x'\n",
    "        y_col = 'loc_d'+str(d)+'n'+str(n)+'_y'\n",
    "        \n",
    "        angles = np.pi * np.random.uniform(0, 2, len(indu_q))\n",
    "        x_d = dist[d] * np.cos(angles); y_d = dist[d] * np.sin(angles)\n",
    "        # jittered q locations to column\n",
    "        jit_values = np.array([x_0, y_0]).T + np.array([x_d, y_d]).T\n",
    "        \n",
    "        indu_q[x_col] = jit_values[:, 0]\n",
    "        indu_q[y_col] = jit_values[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_grid(df, log10_size, x_col, y_col):\n",
    "    grouped = df.groupby([df[x_col].round(-log10_size), df[y_col].round(-log10_size)])\n",
    "    return grouped\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cov_results = np.zeros((D, N))\n",
    "\n",
    "\n",
    "for d in range(D):\n",
    "    for n in range(N):\n",
    "        print(d, n)\n",
    "        x_col = 'loc_d'+str(d)+'n'+str(n)+'_x'\n",
    "        y_col = 'loc_d'+str(d)+'n'+str(n)+'_y'\n",
    "        indu_q_i = indu_q[['CAPACITY', x_col, y_col]]\n",
    "        indu_q_i['geometry'] = list(zip(indu_q_i[x_col], indu_q_i[y_col]))\n",
    "        indu_q_i['geometry'] = indu_q_i['geometry'].apply(Point)\n",
    "        indu_q_i = gpd.GeoDataFrame(indu_q_i)\n",
    "\n",
    "        # Tell which are the counties\n",
    "#         indu_q_i = gpd.sjoin(indu_q_i, gdf, op='within')\n",
    "        \n",
    "        df = pd.concat([groupby_grid(indu_p, 2, 'loc_x', 'loc_y')[['CAPACITY']].sum(), \n",
    "                           groupby_grid(indu_q_i, 2, x_col, y_col)[['CAPACITY']].sum()], axis = 1).fillna(0)\n",
    "        normed = df/df.sum()\n",
    "        dot = normed.iloc[:, 0].dot(normed.iloc[:, 1])\n",
    "        #cosine, but it's a normalization, so that \n",
    "\n",
    "        cov_results[d, n] = np.log10(dot) - np.log10(sum(normed.iloc[:, 0]*normed.iloc[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flap(x, y, t, b, xm, ym):\n",
    "#     print(np.sqrt((x-xm)**2 + (y-ym)**2)/b < 5) \n",
    "#     if (abs(x-xm) < 5*b) and (abs(y-ym) < 5*b):\n",
    "#         i = t*np.exp(-np.sqrt((x-xm)**2 + (y-ym)**2)/b)/(2*b)\n",
    "#     else:\n",
    "#         i = 0\n",
    "#     return i\n",
    "\n",
    "import numexpr as ne\n",
    "\n",
    "def flap(x, y, t, b, xm, ym):\n",
    "    w = np.sqrt((x-xm)**2 + (y-ym)**2)\n",
    "    return t*ne.evaluate('exp(-w/b)/(2*b)')\n",
    "\n",
    "x_min = indu_q[[col for col in indu_q.columns if '_x' in col]].min().min()\n",
    "x_max = indu_q[[col for col in indu_q.columns if '_x' in col]].max().max()\n",
    "y_min = indu_q[[col for col in indu_q.columns if '_y' in col]].min().min()\n",
    "y_max = indu_q[[col for col in indu_q.columns if '_y' in col]].max().max()\n",
    "\n",
    "def sum_pdfs(df, x = np.arange(x_min, x_max, 2), y = np.arange(y_min, y_max, 2)): # grid every 500 mts\n",
    "    xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "    z_cum = np.zeros((len(y), len(x)))\n",
    "    for v in df.values[:3]:\n",
    "        z = flap(xx, yy, v[0], v[1], v[2], v[3])\n",
    "        z_cum = z_cum + z\n",
    "    return z_cum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_cump = sum_pdfs(industry_p[['CAPACITY', 'b', 'x', 'y']])\n",
    "# h = plt.contourf(x,y,z_cump)\n",
    "# plt.show()\n",
    "\n",
    "widths = np.array([10, 30, 60]) # influence radios in km\n",
    "\n",
    "B = len(widths)\n",
    "# N = 3\n",
    "int_results = np.zeros((B, D, N))\n",
    "\n",
    "for d in range(D):\n",
    "    for n in range(N):\n",
    "        x_col = 'loc_d'+str(d)+'n'+str(n)+'_x'\n",
    "        y_col = 'loc_d'+str(d)+'n'+str(n)+'_y'\n",
    "        print(d, n)\n",
    "\n",
    "        for b in range(B):\n",
    "            indu_p['b'] = widths[b]\n",
    "            indu_q['b'] = widths[b]\n",
    "\n",
    "            z_cump = sum_pdfs(indu_p[['CAPACITY', 'b', 'loc_x', 'loc_y']])\n",
    "            z_cumq = sum_pdfs(indu_q[['CAPACITY', 'b', x_col, y_col]])\n",
    "            z_cump = z_cump/sum(sum(z_cump))\n",
    "            z_cumq = z_cumq/sum(sum(z_cumq))\n",
    "            \n",
    "#             dot_list += [sum(sum(z_cump * z_cumq))] # == np.dot(z_cump.flatten(), z_cumq.flatten())\n",
    "#             cov_list += [np.cov(z_cump.flatten(), z_cumq.flatten())[1, 0]]\n",
    "#             h = plt.contourf(x,y,z_cump * z_cumq)\n",
    "#             plt.show()\n",
    "            \n",
    "#             dot = np.vstack([widths, np.log10(dot_list)]).T\n",
    "#             print()\n",
    "            int_results[b, d, n] = np.log10(sum(sum(z_cump * z_cumq))) - np.log10(sum(sum(z_cump * z_cump)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont = pd.DataFrame(int_results.mean(-1), columns = dist, index = widths)\n",
    "df_disc = pd.DataFrame(cov_results, index = dist, columns=range(N)).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (7, 5))\n",
    "\n",
    "np.power(10, df_disc).plot(marker = 'o', ax = ax)\n",
    "np.power(10, df_cont).T.plot(marker = '.', ax = ax)\n",
    "plt.xscale('log')\n",
    "\n",
    "# for b in range(B):\n",
    "#     ax.axhline(np.log10(sum((indu_p['CAPACITY']/indu_p['CAPACITY'].sum())**2)) - np.log10(4*b), linestyle = '--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indu_p.groupby(['STATE','COUNTY']).count().sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR = gpd.read_file('NG_point_2.shp')\n",
    "OR.crs = {'init': 'epsg:4326'}\n",
    "OR = OR.merge(state_ref[['STATE', 'STATEFP']])\n",
    "OR = gpd.sjoin(OR, gdf, op='within')\n",
    "\n",
    "OR['TOTAL_Mbpd'] = OR['CAPACITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR = gpd.read_file('U.S._Petroleum_Refineries/U.S._Petroleum_Refineries.shp')#.merge(state_ref[['STATE', 'STATEFP']])\n",
    "OR = gpd.sjoin(OR, gdf, op='within')\n",
    "\n",
    "OR['TOTAL_Mbpd'] = OR[['AD_Mbpd','VDist_Mbpd','CaDis_Mbpd','VRedu_Mbpd','CaRef_Mbpd','Isal_Mbpd','HDS_Mbpd','Cokin_Mbpd','Asph_Mbpd']].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sqrt(counties.ALAND), 300)\n",
    "plt.xlim(0, 100000)\n",
    "plt.show()\n",
    "\n",
    "# Typical county size of 40x40km. That is .36 in latitude and .42 in long, approx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "industry_p = NG[['CAPACITY', 'STATE', 'COUNTY', 'ALAND', 'AREA_FIPS', 'geometry']].reset_index(drop = True)#[['COUNTY','ALAND']].drop_duplicates().sort_values(by = 'ALAND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_q = OR[['TOTAL_Mbpd', 'ALAND', 'AREA_FIPS', 'geometry']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([industry_p.groupby('AREA_FIPS')[['CAPACITY']].sum(), \n",
    "           industry_q.groupby('AREA_FIPS')[['TOTAL_Mbpd']].sum()], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "log_df = np.log10(df/df.sum()).dropna()\n",
    "log_df.plot(x = 'TOTAL_Mbpd', y = 'CAPACITY', marker = 'o', linewidth = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "industry_p['x'] = [p.x for p in industry_p.geometry]\n",
    "industry_p['y'] = [p.y for p in industry_p.geometry]\n",
    "industry_p['b'] = 1\n",
    "industry_p.plot(markersize = 'CAPACITY', alpha = .1)\n",
    "plt.xlim(-125, -75)\n",
    "plt.ylim(25, 50)\n",
    "\n",
    "industry_q['x'] = [p.x for p in industry_q.geometry]\n",
    "industry_q['y'] = [p.y for p in industry_q.geometry]\n",
    "industry_q['b'] = 1\n",
    "industry_q.plot(markersize = 'TOTAL_Mbpd', alpha = .1)\n",
    "plt.xlim(-125, -75)\n",
    "plt.ylim(25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flap(x, y, t, b, xm, ym):\n",
    "    return t*np.exp(-np.sqrt((x-xm)**2 + (y-ym)**2)/b)/(2*b)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = np.arange(-125, -75, 0.1)\n",
    "y = np.arange(25, 50, 0.1)\n",
    "xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "\n",
    "\n",
    "def sum_pdfs(df, x = np.arange(-125, -75, 0.1), y = np.arange(25, 50, 0.1)):\n",
    "    xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "    z_cum = np.zeros((len(y), len(x)))\n",
    "    for v in df.values:\n",
    "        z = flap(xx, yy, v[0], v[1], v[2], v[3])\n",
    "        z_cum = z_cum + z\n",
    "    return z_cum\n",
    "    \n",
    "z_cump = sum_pdfs(industry_p[['CAPACITY', 'b', 'x', 'y']])\n",
    "h = plt.contourf(x,y,z_cump)\n",
    "plt.show()\n",
    "    \n",
    "z_cumq = sum_pdfs(industry_q[['TOTAL_Mbpd', 'b', 'x', 'y']])\n",
    "h = plt.contourf(x,y,z_cumq)\n",
    "plt.show()\n",
    "\n",
    "h = plt.contourf(x,y,z_cump * z_cumq)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_norm = df\n",
    "df_norm = df/df.sum()\n",
    "df_norm['product'] = df_norm['TOTAL_Mbpd'] * df_norm['CAPACITY']\n",
    "df_norm = df_norm.reset_index().rename(columns={'index':'AREA_FIPS'})\n",
    "gpd.GeoDataFrame(df_norm.dropna().merge(gdf)).plot('product', cmap = 'gray_r')\n",
    "plt.xlim(-125, -75)\n",
    "plt.ylim(25, 50)\n",
    "plt.show()\n",
    "\n",
    "dot_list = []\n",
    "cov_list = []\n",
    "B = np.array([.1, .2, .3, .4, .5, .6, .8,  1, 1.25, 1.5, 2.2])\n",
    "\n",
    "for b in B:\n",
    "    industry_p['b'] = b\n",
    "    industry_q['b'] = b\n",
    "\n",
    "    z_cump = sum_pdfs(industry_p[['CAPACITY', 'b', 'x', 'y']])\n",
    "    z_cumq = sum_pdfs(industry_q[['TOTAL_Mbpd', 'b', 'x', 'y']])\n",
    "    z_cump = .5*z_cump/sum(sum(z_cump))\n",
    "    z_cumq = .5*z_cumq/sum(sum(z_cumq))\n",
    "    dot_list += [sum(sum(z_cump * z_cumq))] # == np.dot(z_cump.flatten(), z_cumq.flatten())\n",
    "    cov_list += [np.cov(z_cump.flatten(), z_cumq.flatten())[1, 0]]\n",
    "    h = plt.contourf(x,y,z_cump * z_cumq)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cov vs corr... \n",
    "# data = np.log10(np.vstack([cov_list, dot_list]).T)\n",
    "# plt.scatter(x = data[:, 0], y = data[:, 1])\n",
    "\n",
    "dot = np.vstack([B, np.log10(dot_list)]).T\n",
    "# cov = np.vstack([B, np.log10(cov_list)]).T\n",
    "# data = cov\n",
    "# plt.scatter(x = data[:, 0], y = data[:, 1])\n",
    "data = dot\n",
    "plt.scatter(x = data[:, 0], y = data[:, 1])\n",
    "plt.axhline(np.log10(abs(np.cov((df/df.sum()).dropna().T)[1, 0])))\n",
    "\n",
    "# plt.xlim(0, 12)\n",
    "# plt.ylim(-12, -5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x = data[:, 0], y = data[:, 1])\n",
    "data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
